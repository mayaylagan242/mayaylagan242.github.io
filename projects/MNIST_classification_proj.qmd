---
title: "Intro to Classification MLP"
description: "description of first post"
author: "Maya"
date: "1/31/2025"
categories:
  - pytorch
  - neural networks
execute: 
  freeze: true
  cache: true
---



# Basic Neural Network Project

This project demonstrates a basic neural network implementation using Python and PyTorch.

## Introduction

Neural networks are a set of algorithms, modeled loosely after the human brain, that are designed to recognize patterns. They interpret sensory data through a kind of machine perception, labeling, or clustering of raw input.

## Implementation

```{python}
import torch
import numpy as np

# Set seed for reproducibility
torch.manual_seed(42)
np.random.seed(42)

print(torch.__version__)
print(torch.cuda.is_available())

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

```


```{python}
import numpy as np
import torchvision
import matplotlib.pyplot as plt
from time import time
from torchvision import datasets, transforms
from torch import nn, optim
```


# Data Cleaning

## Data Transformation

First we will define how we will transform all of the input data to train the model. First we will pull the bitmap into tensors that have separated the array of pixels into 3 color channels (RGB) with each pixel for that channel having a value from 0 to 255. Then we scale the values down to 0-1 and then normalized with a mean and standard deviation 

```{python}
transform = transforms.Compose(
  [
    transforms.ToTensor(),
    transforms.Normalize((0.5,), (0.5,)),
  ]
)
```

## Data Collection

```{python}
trainset = datasets.MNIST(
  'data/MNIST/trainset', 
  download=True, 
  train=True, 
  transform=transform
)

valset = datasets.MNIST(
  'data/MNIST/valset', 
  download=True, 
  train=False, 
  transform=transform
)

trainloader = torch.utils.data.DataLoader(
  trainset, 
  batch_size=64, 
  shuffle=True
)

valloader = torch.utils.data.DataLoader(
  valset, 
  batch_size=64, 
  shuffle=True
)

```





## Explore Data Structure

```{python}
dataiter = iter(trainloader)
images, labels = next(dataiter)

print(images.shape)
print(labels.shape)
```

There are 64 images in each batch where each image is 28 pixels x 28 pixels

The labels have one dimension of 64 labels for the corresponding image!

## View Image


### One Image

```{python}
plt.imshow(images[0].numpy().squeeze(), cmap='gray_r')
```

### Multiple Images

```{python}
# make a plot of 25 images in a 5x5 grid
figure = plt.figure(figsize=(8, 8))
cols, rows = 5, 5
for i in range(1, cols * rows + 1):
  img = images[i - 1].squeeze()
  ax = figure.add_subplot(rows, cols, i)
  ax.imshow(img, cmap="gray_r")
  # add title
  ax.set_title(labels[i - 1].item(), y=1, pad=1.5)

  # clean up subplot axes
  ax.tick_params(axis='both', which='both', length=0)
  ax.set_xticklabels([])
  ax.set_yticklabels([])
  # make axes thicker
  for spine in ax.spines.values():
    spine.set_edgecolor('black')
    spine.set_linewidth(1.5)

plt.show()
```

# Neural Network

```{python}
input_size = 28*28
hidden_sizes = [128, 64]
output_size = 10

model = nn.Sequential(
  nn.Linear(input_size, hidden_sizes[0]),
  nn.ReLU(),
  nn.Linear(hidden_sizes[0], hidden_sizes[1]),
  nn.ReLU(),
  nn.Linear(hidden_sizes[1], output_size),
  nn.LogSoftmax(dim=1)
)

print(model)
```


$$
\text{LogSoftmax}(x_i) = \log \left( \frac{e^{x_i}}{\sum_{j} e^{x_j}} \right)
$$


$$
\text{ReLU}(x) = \max(0, x)
$$


## Loss



```{python}
criterion = nn.NLLLoss()
images, labels = next(iter(trainloader))
images = images.view(images.shape[0], -1)
labels = labels

logps = model(images) #log probabilities
loss = criterion(logps, labels) #calculate the NLL loss
```


## Move to CUDA

```{python}
model.to(device)
model_device = next(model.parameters()).device
print(f"Model is on device: {model_device}")
```


## Train

```{python}
optimizer = optim.SGD(model.parameters(), lr=0.003, momentum=0.9)
time0 = time()
epochs = 15

for e in range(epochs):
  running_loss = 0
  for images, labels in trainloader:
    # Flatten MNIST images into a 784 long vector and move to CUDA
    images = images.view(images.shape[0], -1).to(device)
    labels = labels.to(device)
  
    # Training pass
    optimizer.zero_grad()
    
    output = model(images)
    loss = criterion(output, labels)
    
    # This is where the model learns by backpropagating
    loss.backward()
    
    # And optimizes its weights here
    optimizer.step()
    
    running_loss += loss.item()
  else:
    print(f"Epoch {e} - Training loss: {running_loss/len(trainloader)}")
    print("\nTraining Time (in minutes) =",(time()-time0)/60)
```



## Evaluation

```{python}
def view_classify(img, ps):
    ''' Function for viewing an image and it's predicted classes.
    '''
    ps = ps.data.numpy().squeeze()

    fig, (ax1, ax2) = plt.subplots(figsize=(6,9), ncols=2)
    ax1.imshow(img.resize_(1, 28, 28).numpy().squeeze())
    ax1.axis('off')
    ax2.barh(np.arange(10), ps)
    ax2.set_aspect(0.1)
    ax2.set_yticks(np.arange(10))
    ax2.set_yticklabels(np.arange(10))
    ax2.set_title('Class Probability')
    ax2.set_xlim(0, 1.1)
    plt.tight_layout()
```

```{python}
model.to("cpu")
images, labels = next(iter(valloader))

img = images[0].view(1, 784)

with torch.no_grad():
    logps = model(img)

ps = torch.exp(logps)
probab = list(ps.numpy()[0])
print("Predicted Digit =", probab.index(max(probab)))
view_classify(img.view(1, 28, 28), ps)
```




```{python}
correct_count, all_count = 0, 0
for images,labels in valloader:
  for i in range(len(labels)):
    img = images[i].view(1, 784)
    with torch.no_grad():
        logps = model(img)

    
    ps = torch.exp(logps)
    probab = list(ps.numpy()[0])
    pred_label = probab.index(max(probab))
    true_label = labels.numpy()[i]
    if(true_label == pred_label):
      correct_count += 1
    all_count += 1

print("Number Of Images Tested =", all_count)
print("\nModel Accuracy =", (correct_count/all_count))
```





```{python}
# assess accuracy by class
class_correct = list(0. for i in range(10))
class_total = list(0. for i in range(10))

with torch.no_grad():
  for images, labels in valloader:
    images = images.view(images.shape[0], -1)
    outputs = model(images)
    _, predicted = torch.max(outputs, 1)
    c = (predicted == labels).squeeze()
    for i in range(len(labels)):
      label = labels[i]
      class_correct[label] += c[i].item()
      class_total[label] += 1

# Calculate average accuracy
average_accuracy = correct_count/all_count * 100

# Plot accuracy by class
fig, ax = plt.subplots()
classes = list(range(10))
accuracies = [100 * class_correct[i] / class_total[i] if class_total[i] > 0 else 0 for i in classes]

ax.bar(classes, accuracies, color='blue')
ax.axhline(y=average_accuracy, color='red', linestyle='--', label=f'Average Accuracy: {average_accuracy:.2f}%')

ax.set_xlabel('Class')
ax.set_ylabel('Accuracy (%)')
ax.set_title('Accuracy by Class')
ax.set_xticks(classes)
ax.set_xticklabels(classes)
ax.legend()

plt.show()
```



```{python}
# find which classes were most often misclassified as the other classes

from sklearn.metrics import confusion_matrix
import seaborn as sns

# Initialize the prediction and true label lists
all_preds = []
all_labels = []

# Collect all predictions and true labels
with torch.no_grad():
  for images, labels in valloader:
    images = images.view(images.shape[0], -1)
    outputs = model(images)
    _, predicted = torch.max(outputs, 1)
    all_preds.extend(predicted.numpy())
    all_labels.extend(labels.numpy())

# Compute the confusion matrix
conf_matrix = confusion_matrix(all_labels, all_preds)

# Plot the confusion matrix
plt.figure(figsize=(10, 8))
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=classes, yticklabels=classes)
plt.xlabel('Predicted')
plt.ylabel('True')
plt.title('Confusion Matrix')
plt.show()
```